{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f1996dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-3f907bf17b98>:16: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk.sentiment\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "import re\n",
    "from time import strftime\n",
    "\n",
    "import unicodedata\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "# Turn off pink boxes for demo\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "import acquire \n",
    "import prepare\n",
    "import model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df26299",
   "metadata": {},
   "source": [
    "### Modeling Notes:\n",
    "    - Modelling was run using TF-IDF Logistic Regression, Bag of Words Decision Tree, & Bag of Words Random Forest\n",
    "\n",
    "    - Baseline was created by defining the most common language frequency Python:\n",
    "        - 46.4%\n",
    "    \n",
    "    - Bag of Words Decision Tree (6=depth) ran the best at:\n",
    "        Train Accuracy : (input)\n",
    "        Validate Accuracy: (input)\n",
    "        \n",
    "    - Reference model_results.ipynb to see all other models performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77f4851c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 46.03%\n"
     ]
    }
   ],
   "source": [
    "# Defining our baseline accuracy by the most common language frequency\n",
    "model.baseline_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c374216e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 74.29%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual      C#  Java  JavaScript  Python  TypeScript\n",
      "predicted                                           \n",
      "Java        0   2     0           0       0         \n",
      "JavaScript  0   0     18          0       0         \n",
      "Python      6   5     0           32      7         \n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          C#       0.00      0.00      0.00         6\n",
      "        Java       1.00      0.29      0.44         7\n",
      "  JavaScript       1.00      1.00      1.00        18\n",
      "      Python       0.64      1.00      0.78        32\n",
      "  TypeScript       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.74        70\n",
      "   macro avg       0.53      0.46      0.44        70\n",
      "weighted avg       0.65      0.74      0.66        70\n",
      "\n",
      "----------------------------------------------\n",
      "Validate Accuracy: 46.67%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual     C#  Java  JavaScript  Python  TypeScript\n",
      "predicted                                          \n",
      "Python     3   3     7           14      3         \n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          C#       0.00      0.00      0.00         3\n",
      "        Java       0.00      0.00      0.00         3\n",
      "  JavaScript       0.00      0.00      0.00         7\n",
      "      Python       0.47      1.00      0.64        14\n",
      "  TypeScript       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.47        30\n",
      "   macro avg       0.09      0.20      0.13        30\n",
      "weighted avg       0.22      0.47      0.30        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model ran on tfidf logistic regression\n",
    "model.logistic_regression_tfidf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83b56a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.57%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual          C#  Java  JavaScript  Python  TypeScript\n",
      "tree_predicted                                          \n",
      "C#              3   0     0           0       0         \n",
      "Java            0   6     0           0       0         \n",
      "JavaScript      0   1     17          0       1         \n",
      "Python          0   0     1           31      1         \n",
      "TypeScript      3   0     0           1       5         \n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          C#       1.00      0.50      0.67         6\n",
      "        Java       1.00      0.86      0.92         7\n",
      "  JavaScript       0.89      0.94      0.92        18\n",
      "      Python       0.94      0.97      0.95        32\n",
      "  TypeScript       0.56      0.71      0.63         7\n",
      "\n",
      "    accuracy                           0.89        70\n",
      "   macro avg       0.88      0.80      0.82        70\n",
      "weighted avg       0.90      0.89      0.88        70\n",
      "\n",
      "----------------------------------------------\n",
      "Validate Accuracy: 50.00%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual          C#  Java  JavaScript  Python  TypeScript\n",
      "tree_predicted                                          \n",
      "Java            2   1     0           1       0         \n",
      "JavaScript      1   0     3           0       1         \n",
      "Python          0   2     4           11      2         \n",
      "TypeScript      0   0     0           2       0         \n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          C#       0.00      0.00      0.00         3\n",
      "        Java       0.25      0.33      0.29         3\n",
      "  JavaScript       0.60      0.43      0.50         7\n",
      "      Python       0.58      0.79      0.67        14\n",
      "  TypeScript       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.50        30\n",
      "   macro avg       0.29      0.31      0.29        30\n",
      "weighted avg       0.44      0.50      0.46        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model ran using bag of words decision tree (max depth = 5)\n",
    "model.BoW_Decision_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f739ceb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.43%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual            C#  Java  JavaScript  Python  TypeScript\n",
      "forest_predicted                                          \n",
      "C#                5   0     0           0       0         \n",
      "Java              0   6     0           0       0         \n",
      "JavaScript        0   0     16          0       0         \n",
      "Python            1   1     2           32      2         \n",
      "TypeScript        0   0     0           0       5         \n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          C#       1.00      0.83      0.91         6\n",
      "        Java       1.00      0.86      0.92         7\n",
      "  JavaScript       1.00      0.89      0.94        18\n",
      "      Python       0.84      1.00      0.91        32\n",
      "  TypeScript       1.00      0.71      0.83         7\n",
      "\n",
      "    accuracy                           0.91        70\n",
      "   macro avg       0.97      0.86      0.90        70\n",
      "weighted avg       0.93      0.91      0.91        70\n",
      "\n",
      "----------------------------------------------\n",
      "Validate Performance: 53.33%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual            C#  Java  JavaScript  Python  TypeScript\n",
      "forest_predicted                                          \n",
      "Java              1   0     0           0       0         \n",
      "JavaScript        0   0     2           0       0         \n",
      "Python            2   3     5           14      3         \n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          C#       0.00      0.00      0.00         3\n",
      "        Java       0.00      0.00      0.00         3\n",
      "  JavaScript       1.00      0.29      0.44         7\n",
      "      Python       0.52      1.00      0.68        14\n",
      "  TypeScript       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.53        30\n",
      "   macro avg       0.30      0.26      0.23        30\n",
      "weighted avg       0.48      0.53      0.42        30\n",
      "\n",
      "Accuracy: 78.57%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual          C#  Java  JavaScript  Python  TypeScript\n",
      "tree_predicted                                          \n",
      "C#              1   0     0           1       0         \n",
      "Java            0   6     0           0       0         \n",
      "JavaScript      0   0     12          0       0         \n",
      "Python          2   0     1           30      1         \n",
      "TypeScript      3   1     5           1       6         \n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          C#       0.50      0.17      0.25         6\n",
      "        Java       1.00      0.86      0.92         7\n",
      "  JavaScript       1.00      0.67      0.80        18\n",
      "      Python       0.88      0.94      0.91        32\n",
      "  TypeScript       0.38      0.86      0.52         7\n",
      "\n",
      "    accuracy                           0.79        70\n",
      "   macro avg       0.75      0.70      0.68        70\n",
      "weighted avg       0.84      0.79      0.79        70\n",
      "\n",
      "----------------------------------------------\n",
      "Validate Accuracy: 46.67%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual          C#  Java  JavaScript  Python  TypeScript\n",
      "tree_predicted                                          \n",
      "C#              0   0     1           0       0         \n",
      "Java            2   1     0           1       0         \n",
      "JavaScript      1   0     2           0       1         \n",
      "Python          0   2     3           11      2         \n",
      "TypeScript      0   0     1           2       0         \n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          C#       0.00      0.00      0.00         3\n",
      "        Java       0.25      0.33      0.29         3\n",
      "  JavaScript       0.50      0.29      0.36         7\n",
      "      Python       0.61      0.79      0.69        14\n",
      "  TypeScript       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.47        30\n",
      "   macro avg       0.27      0.28      0.27        30\n",
      "weighted avg       0.43      0.47      0.43        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model ran using bag of words for random forest (max depth = 8)\n",
    "model.BoW_Random_Forest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f2fd6b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running unseen data on bag of words random forest model\n",
    "#model.test_model_rf()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce055b64",
   "metadata": {},
   "source": [
    "### Modeling Conclusions:\n",
    "    - All models performed tested better on the larger datasets (train > validate > test)\n",
    "    - Though our test model performed slightly better than baseline we believe that if you run this model through a larger number of Git repos it will perform stronger.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5d16e4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Don't Pull Anything Bellow this Line ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe91c200",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cee801f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86af415b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # code necessary for bag of words\n",
    "\n",
    "# raw_data = acquire.scrape_github_data()\n",
    "# train, validate, test = prepare.split_data()\n",
    "# #Using CountVectorizer for Bag of Words - defining X & y(target variable)\n",
    "# cv = CountVectorizer()\n",
    "# X = cv.fit_transform(train.lemmatized)\n",
    "# y = train.language\n",
    "# # function as above\n",
    "# X_train, y_train, X_validate, y_validate, X_test, y_test = model.X_train_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29426467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c359372e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6635bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70db94e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "raw_data = acquire.scrape_github_data()\n",
    "train, validate, test = prepare.split_data()\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0965443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Vectorizer using bag of words - defining X & y variables\n",
    "#pull csv\n",
    "raw_data = acquire.scrape_github_data()\n",
    "train, validate, test = prepare.split_data()\n",
    "#Using CountVectorizer for Bag of Words - defining X & y(target variable)\n",
    "cv = CountVectorizer()\n",
    "\n",
    "### note if you want to add more features add onto next line, make sure the column is on train and entered as a list\n",
    "### remove this comment for final notebook if we don't use\n",
    "X = cv.fit_transform(train.lemmatized)\n",
    "y = train.language\n",
    "# function as above\n",
    "X_train, y_train, X_validate, y_validate, X_test, y_test = model.X_train_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1795e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f0b877",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.language.value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a75046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate.language.value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f379bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.language.value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b130058c",
   "metadata": {},
   "outputs": [],
   "source": [
    "58+31+13+12+11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c40ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "58/125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804a9184",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.baseline_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b15e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best model\n",
    "model.BoW_Decision_tree(X_train, y_train, X_validate, y_validate, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d57ac4c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Pull for final notebook, run last thing as this is our final test\n",
    "\n",
    "model.test_model(X_train, y_train, X_validate, y_validate, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6a4ce9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b840be6e",
   "metadata": {},
   "source": [
    "We can add the test conclusions after we get the results for the final notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e16165",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Stephanie add all the above lines for the final notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f7ca26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08e3a68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f13959",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = acquire.scrape_github_data()\n",
    "train, validate, test = prepare.split_data()\n",
    "\n",
    "#double checking\n",
    "print ('train ===>', train.shape)\n",
    "print ('validate ===>', validate.shape)\n",
    "print('test===>', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec28a418",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Value Counts for our train dataset\n",
    "\n",
    "train.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b3e5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### function for further splitting has stratify\n",
    "\n",
    "def X_train_split(X_data, y_data):\n",
    "    ''' Further splitting for X & y train,validate,test\n",
    "    '''\n",
    "    X_train_validate, X_test, y_train_validate, y_test = train_test_split(X_data, y_data, \n",
    "                                                                          stratify = y_data, \n",
    "                                                                          test_size=.2, random_state=123)\n",
    "    \n",
    "    X_train, X_validate, y_train, y_validate = train_test_split(X_train_validate, y_train_validate, \n",
    "                                                                stratify = y_train_validate, \n",
    "                                                                test_size=.3, \n",
    "                                                                random_state=123)\n",
    "    \n",
    "    return X_train, y_train, X_validate, y_validate, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d766d19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining baseline accuracy by most common language frequency = Python\n",
    "Baseline_Accuracy = round(max(train.language.value_counts()) / train.shape[0] *100,2)\n",
    "\n",
    "print(f'Baseline Accuracy: {round(max(train.language.value_counts()) / train.shape[0] *100,2)}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e17680a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definig TfidVectorizer for X and y\n",
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(train.lemmatized)\n",
    "y = train.language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a70372f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting X_train_split\n",
    "X_train, y_train, X_validate, y_validate, X_test, y_test = X_train_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac442518",
   "metadata": {},
   "source": [
    "### Logistic Regression TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6682e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "#form predictions\n",
    "train['predicted'] = lm.predict(X_train)\n",
    "validate['predicted'] = lm.predict(X_validate)\n",
    "test['predicted'] = lm.predict(X_test)\n",
    "print('Train Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.predicted))\n",
    "print('----------------------------------------------')\n",
    "print('Validate Accuracy: {:.2%}'.format(accuracy_score(validate.actual, validate.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(validate.predicted, validate.actual))\n",
    "print('---')\n",
    "print(classification_report(validate.actual, validate.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f96f688",
   "metadata": {},
   "source": [
    "### Decision Tree TF-IDF (depth = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdef025",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=4).fit(X_train, y_train)\n",
    "train['tree_predicted'] = tree.predict(X_train)\n",
    "validate['tree_predicted'] = tree.predict(X_validate)\n",
    "test['tree_predicted'] = tree.predict(X_test)\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.tree_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.tree_predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.tree_predicted))\n",
    "print('----------------------------------------------')\n",
    "print('Validate Accuracy: {:.2%}'.format(accuracy_score(validate.actual, validate.tree_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(validate.tree_predicted, validate.actual))\n",
    "print('---')\n",
    "print(classification_report(validate.actual, validate.tree_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795d74fd",
   "metadata": {},
   "source": [
    "### Random Forest TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b54c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "\n",
    "forest = RandomForestClassifier(min_samples_leaf = 1, max_depth = 5, random_state= 123).fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "train['forest_predicted'] = forest.predict(X_train)\n",
    "validate['forest_predicted'] = forest.predict(X_validate)\n",
    "test['forest_predicted'] = forest.predict(X_test)\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.forest_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.forest_predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.forest_predicted))\n",
    "print('----------------------------------------------')\n",
    "print('Validate Accuracy: {:.2%}'.format(accuracy_score(validate.actual, validate.forest_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(validate.forest_predicted, validate.actual))\n",
    "print('---')\n",
    "print(classification_report(validate.actual, validate.forest_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d4decd",
   "metadata": {},
   "source": [
    "# Implementing Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bd90d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = acquire.scrape_github_data()\n",
    "train, validate, test = prepare.split_data()\n",
    "###\n",
    "\n",
    "# Count Vectorizer using bag of words - defining X & y variables\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(train.lemmatized)\n",
    "y = train.language\n",
    "\n",
    "# function as above\n",
    "X_train, y_train, X_validate, y_validate, X_test, y_test = X_train_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26f1658",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806619f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd8329d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada94e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2ad0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_bag_of_words.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561ac572",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101d6d20",
   "metadata": {},
   "source": [
    "### Logistic Regression Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88130300",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "#form predictions\n",
    "train['predicted'] = lm.predict(X_train)\n",
    "validate['predicted'] = lm.predict(X_validate)\n",
    "test['predicted'] = lm.predict(X_test)\n",
    "print('Train Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.predicted))\n",
    "print('----------------------------------------------')\n",
    "print('Validate Accuracy: {:.2%}'.format(accuracy_score(validate.actual, validate.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(validate.predicted, validate.actual))\n",
    "print('---')\n",
    "print(classification_report(validate.actual, validate.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c92480",
   "metadata": {},
   "source": [
    "### Bag of Words Decision Tree (depth = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac7da39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=5).fit(X_train, y_train)\n",
    "train['tree_predicted'] = tree.predict(X_train)\n",
    "validate['tree_predicted'] = tree.predict(X_validate)\n",
    "test['tree_predicted'] = tree.predict(X_test)\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.tree_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.tree_predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.tree_predicted))\n",
    "print('----------------------------------------------')\n",
    "print('Validate Accuracy: {:.2%}'.format(accuracy_score(validate.actual, validate.tree_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(validate.tree_predicted, validate.actual))\n",
    "print('---')\n",
    "print(classification_report(validate.actual, validate.tree_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7da687",
   "metadata": {},
   "source": [
    "### Random Forest Bag of Words\n",
    "    - play with max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d401b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "\n",
    "forest = RandomForestClassifier(min_samples_leaf = 1, max_depth = 8, random_state= 123).fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "train['forest_predicted'] = forest.predict(X_train)\n",
    "validate['forest_predicted'] = forest.predict(X_validate)\n",
    "test['forest_predicted'] = forest.predict(X_test)\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.forest_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.forest_predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.forest_predicted))\n",
    "print('----------------------------------------------')\n",
    "print('Validate Performance: {:.2%}'.format(accuracy_score(validate.actual, validate.forest_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(validate.forest_predicted, validate.actual))\n",
    "print('---')\n",
    "print(classification_report(validate.actual, validate.forest_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468fd271",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate.actual.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e459ec68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec488f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_forest(X_train, y_train, X_validate, y_validate, X_test, y_test):\n",
    "    train = pd.DataFrame(dict(actual=y_train))\n",
    "    validate = pd.DataFrame(dict(actual=y_validate))\n",
    "    test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "\n",
    "    train['forest_predicted'] = forest.predict(X_train)\n",
    "    validate['forest_predicted'] = forest.predict(X_validate)\n",
    "    test['forest_predicted'] = forest.predict(X_test)\n",
    "\n",
    "    print('Accuracy: {:.2%}'.format(accuracy_score(test.actual, test.tree_predicted)))\n",
    "    print('---')\n",
    "    print('Confusion Matrix')\n",
    "    print(pd.crosstab(test.tree_predicted, test.actual))\n",
    "    print('---')\n",
    "    print(classification_report(test.actual, test.tree_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1685ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(X_train, y_train, X_validate, y_validate, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
